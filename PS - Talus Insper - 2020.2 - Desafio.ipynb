{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROCESSO SELETIVO TALUS INSPER 2020.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ol√°! Esse √© o Jupyter com o desafio do processo seletivo para a Talus!\n",
    "\n",
    "√â aqui que deve ser posta a resolu√ß√£o do desafio que iremos propor e nenhum outro material entregue junto com este ser√° considerado. Antes de continuarmos para o desafio, precisamos que voc√™ se identifique (usu√°rios n√£o identificados podem at√© passar, mas n√£o receber√£o notifica√ß√£o &#128521;\n",
    "\n",
    "Edite essa c√©lula e\n",
    "\n",
    "<font color='red'>Beatriz Carvalho Abr√£o</font>\n",
    "\n",
    "<font color='red'>beatrizca@al.insper.edu.br</font>\n",
    "\n",
    "<font color='red'>beaabrao (Discord e Github)</font>\n",
    "\n",
    "Lembre que n√£o √© obrigat√≥rio Discord nessa etapa, mas ambas Segunda e Terceira Fase ser√£o realizadas por l√°. N√≥s estamos num servidor do Discord especial feito pra voc√™s, voc√™ pode passar l√° e tirar d√∫vidas com nossos membros a qualquer momento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regras do desafio\n",
    "\n",
    "O desafio que propomos aqui √© construir um modelo de regress√£o linear simples para apenas uma vari√°vel.\n",
    "\n",
    "Existem diversas maneiras de fazer isso, a maneira que iremos explicar aqui, e que voc√™ dever√° reproduzir, √© o m√©todo de Gradient Descent. Qualquer outro m√©todo que n√£o este __N√ÉO__ ser√° considerado.\n",
    "\n",
    "Uma an√°lise explorat√≥ria dos dados n√£o √© obrigat√≥ria e nem mesmo necess√°ria!\n",
    "\n",
    "Por √∫ltimo, vale frisar: a utiliza√ß√£o de pacotes com fun√ß√µes que cortem passos ou que fa√ßam o trabalho por voc√™ resultar√° na nulidade de sua solu√ß√£o e __N√ÉO__ ser√° considerado tamb√©m.\n",
    "\n",
    "No entanto, voc√™ pode usar os pacotes que foram ensinados no arquivo de tutorial para esse desafio.\n",
    "\n",
    "Voc√™ ir√° achar algumas c√©lulas com c√≥digo, elas servem para guiar voc√™, mas n√£o s√£o obrigat√≥rias! E voc√™ n√£o precisa usar a estrutura que propomos, mas deve seguir o roteiro que se encontra no fim do desafio!\n",
    "\n",
    "Boa sorte, n√≥s estamos esperando por voc√™ na Talus!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposta de desafio\n",
    "\n",
    "Como dito, o seu desafio ser√° transformar em c√≥digo a teoria sobre modelos de regress√£o linear que ser√° ensinada aqui.\n",
    "\n",
    "Voc√™ usar√° o c√≥digo que criou para prever o comportamento de uma vari√°vel em fun√ß√£o de outra, estas podem ser achadas no dataset 'desafio.csv' na pasta data. As vari√°veis foram geradas manualmente por n√≥s e portanto asseguramos que existe uma rela√ß√£o linear entre elas.\n",
    "\n",
    "No nosso dataset, a vari√°vel que ser√° prevista √© a vari√°vel y. N√£o existe um valor a ser batido, mas existem com certeza valores visivelmente incorretos. Seu c√≥digo n√£o ser√° avaliado apenas pelo valor dos coeficientes, mas tamb√©m (e principalmente) pela qualidade do c√≥digo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explica√ß√£o do modelo\n",
    "\n",
    "Sem entrarmos nos detalhes matem√°ticos (voc√™ ir√° aprender isso conosco depois), uma regress√£o linear √© um modelo capaz de computar o valor de uma vari√°vel atrav√©s de uma soma com pesos de outras vari√°veis mais a adi√ß√£o de uma constante (tamb√©m chamada de vi√©s ou intercepto). De maneira geral, uma rela√ß√£o linear entre vari√°veis pode ser expressa por:\n",
    "\n",
    "$$y = \\theta_0 + \\theta_1x_1 + \\theta_2x_2 + ... \\theta_nx_n$$\n",
    "\n",
    "Aqui trataremos apenas do caso $n = 1$, sendo $n$ o n√∫mero de features ou inputs do nosso modelo.\n",
    "\n",
    "Nessa equa√ß√£o, $\\theta_i$ √© o par√¢metro da feature $i$ sendo $\\theta_0$ o vi√©s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leia nessa c√©lula o dataset \"desafio.csv\" e obtenha os arrays de X e y\n",
    "import pandas as pd \n",
    "\n",
    "dataset = pd.read_csv('C:/Users/Beatriz/Documents/Talus/Fase1_2020-2/data/desafio.csv')\n",
    "\n",
    "X = dataset['X']\n",
    "y = dataset['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os algoritmos de regress√£o linear servem para acharmos, de maneira mais eficiente, os par√¢metros $\\theta$ de nosso modelo, definida uma m√©trica.\n",
    "\n",
    "Portanto, antes de falarmos como construirmos e treinarmos um modelo desses, √© preciso definir nossa m√©trica.\n",
    "\n",
    "Existem diversas m√©tricas de avalia√ß√£o quando falamos de modelos lineares, a mais popular e que usaremos aqui √© o __Erro Quadr√°tico M√©dio__ ou (EQM) que √© dado por:\n",
    "\n",
    "$$EQM(≈∑) = \\frac{1}{m}\\sum^m_{i=1}(≈∑_i - y_i)¬≤$$\n",
    "\n",
    "Onde:\n",
    "\n",
    "$m$ √© o n√∫mero de amostras usada no modelo;\n",
    "\n",
    "$≈∑$ √© o valor previsto por nosso modelo;\n",
    "\n",
    "$y$ √© o valor real da vari√°vel prevista.\n",
    "\n",
    "Substituindo a equa√ß√£o linear na f√≥rmula do EQM ficamos com:\n",
    "\n",
    "$$EQM(≈∑) = \\frac{1}{m}\\sum^m_{i=1}(\\theta_1{x_1}_i + \\theta_0 - y_i)¬≤$$\n",
    "\n",
    "E, portanto, vemos que $EQM$ depende do termo quadr√°tico de $\\theta_1$ e $\\theta_0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crie aqui uma fun√ß√£o que calcule EQM\n",
    "# antes, lembre de inicializar o par√¢metro m do seu modelo\n",
    "\n",
    "m = len(dataset['X'])\n",
    "\n",
    "iteracoes = 2000\n",
    "\n",
    "# os par√¢metros recebidos pela fun√ß√£o ficam a seu crit√©rio\n",
    "\n",
    "def calcula_eqm(m, theta_1, theta_0, yi):\n",
    "    eqm = 1/m * ((theta_1*xi + theta_0 - yi)**2) \n",
    "    return eqm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como dito, existem v√°rias maneiras de encontrar os par√¢metros do nosso modelo, inclusive, um m√©todo bem mais simples do que o que vamos ensinar (mas que √© BEM mais lento para uma quantidade grande de dados).\n",
    "\n",
    "O m√©todo que usaremos se chama *Gradient Descent*, ele √© um algoritmo, ou melhor, uma fam√≠lia de algoritmos, bem simples e gen√©rico capaz de encontrar os par√¢metros de nossa regress√£o de uma maneira mais r√°pida, objetivando minimizar o valor do nosso erro, o $EQM$.\n",
    "\n",
    "Esse m√©todo consiste de inicializar, aleatoriamente, o valor dos par√¢metros e, iterativamente, modificar esse valor em fun√ß√£o do erro obtido.\n",
    "\n",
    "Para explicar bem o procedimento, vamos supor $\\theta_0$ (ou $\\theta_1$) constante. Nesse caso, ter√≠amos que $EQM$ √© uma fun√ß√£o quadr√°tica de $\\theta_1$, ou seja, uma par√°bola.\n",
    "\n",
    "Nesse caso, o gr√°fico de $EQM$ x $\\theta_1$ seria semelhante a:\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/600/1*iNPHcCxIvcm7RwkRaMTx1g.jpeg\" height=\"400\" width=\"600\">\n",
    "\n",
    "Onde cost √© a fun√ß√£o de custo, que no caso √© $EQM$.\n",
    "\n",
    "O que queremos √© dar, pequenos \"passos\", modificando $\\theta_1$ at√© alcan√ßarmos aquele que minimiza nosso erro.\n",
    "\n",
    "Caso voc√™ n√£o tenha entedido ainda, fa√ßamos um exerc√≠cio de imagina√ß√£o: imagine que voc√™ esteja preso no topo de uma montanha durante uma n√©voa muito densa, deixando de lado suas habilidades de alpinismo, uma maneira de achar a base da montanha seria deslizar seu p√© no ch√£o at√© achar a dire√ß√£o de descida e ent√£o dar pequenos passos nessa dire√ß√£o, √© exatamente isso que vamos fazer aqui.\n",
    "\n",
    "O learning step no nosso gr√°fico seria o tamanho do passo que voc√™ daria na montanha e a dire√ß√£o que seu p√© indicaria seria o qu√™? Vamos ver isso agora.\n",
    "\n",
    "Ah, e claro voc√™ esteja se co√ßando que n√£o resolvemos o caso real, com $n$ features, calma, n√£o √© o foco desse desafio e n√£o √© muito diferente da ideia que mostramos aqui, voc√™ s√≥ teria que ter uma abstra√ß√£o maior para desenhar o gr√°fico.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1098/1*yasmQ5kvlmbYMe8eDkyl6w.png\" height=\"400\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T√° certo, mas antes de falar sobre a dire√ß√£o do passo, √© importante falarmos algo sobre o learning step, ou learning rate como iremos chamar agora.\n",
    "\n",
    "Voc√™ se perguntou qual o valor que o learning rate deveria ter? Bom, n√≥s n√£o vamos te dar uma resposta sobre isso, mas vamos te mostrar o que o valor que voc√™ escolheu poderia resultar.\n",
    "\n",
    "Se voc√™ escolher um learning rate muito pequeno, o seu modelo precisaria de muito mais itera√ß√µes e execu√ß√µes para achar o valor de m√≠nimo. √â o equivalente a voc√™ dar passos que mal separam suas pernas tentando descer a montanha.\n",
    "\n",
    "J√° um learning rate muito grande corre o risco de passar do local de m√≠nimo.\n",
    "\n",
    "Veja essas imagens que exemplificam bem isso, mostrando um caso com learning rate pequeno e outro com learning rate muito grande, respectivamente:\n",
    "\n",
    "<div style=\"display: block\">\n",
    "<img src=\"./img/small_lr.png\" height=\"400\" width=\"600\">\n",
    "\n",
    "<img src=\"./img/large_lr.png\" height=\"400\" width=\"600\">\n",
    "</div>\n",
    "\n",
    "O learning rate tamb√©m √© importante para se esquivar de m√≠nimos locais, mas voc√™ n√£o precisa se preocupar com isso aqui."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicialize aqui os par√¢metros learning rate e o theta_0 e theta_1 inicial\n",
    "#    Coment√°rio: Inicialmente chutei valores aleat√≥rios, conforme fui rodando o programa e analisando o gr√°fico, fui calibrando \n",
    "#                os valores de tetha_0 e tetha_1 para fazer um algoritmo com menos itera√ß√µes e com um learning rate um pouco maior.\n",
    "               \n",
    "theta_0 = -8\n",
    "theta_1 = 1.5\n",
    "\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, agora vamos pro √∫ltimo fundamento (e o mais importante) pra que voc√™ possa concluir o desafio.\n",
    "\n",
    "A an√°logo matem√°tico da dire√ß√£o do seu passo tentando descer da montanha √© o que d√° nome a esse algoritmo, o *Gradiente*.\n",
    "\n",
    "Imaginamos que voc√™ esteja familiarizado com o conceito de derivada. Imagine no primeiro gr√°fico que lhe apresentamos que voc√™ tivesse que apontar a dire√ß√£o para onde o valor de $\\theta$ precisa andar, talvez voc√™ tenha feito com o dedo uma linha tangente apontando para o pr√≥ximo ponto do gr√°fico.\n",
    "\n",
    "Devemos achar a tangente, ou mais especificamente, o coeficiente angular desta, para encontrarmos a dire√ß√£o que devemos seguir a fim de minimizar nossa fun√ß√£o.\n",
    "\n",
    "E, uma luz pode ter acendido em voc√™, indicando o que ser√° necess√°rio para tal feito: as derivadas.\n",
    "\n",
    "Se calcularmos a derivada para $\\theta_0$ e $\\theta_1$ ter√≠amos:\n",
    "\n",
    "$$\\frac{\\partial}{\\partial\\theta_0}EQM = \\frac{2}{m}\\sum^m_{i=1}(\\theta_1{x_1}_i + \\theta_0 - y_i)$$\n",
    "\n",
    "$$\\frac{\\partial}{\\partial\\theta_1}EQM = \\frac{2}{m}\\sum^m_{i=1}(\\theta_1{x_1}_i + \\theta_0 - y_i){x_1}_i$$\n",
    "\n",
    "O s√≠mbolo pode parecer diferente, mas a ideia √© a mesma, √© que nesse caso estamos falando de derivada parcial.\n",
    "\n",
    "Ah, e o motivo do nome gradiente, vem porque um gradiente basicamente √© um vetor formado pela derivada parcial das vari√°veis de que depende uma fun√ß√£o e indico sentido e a dire√ß√£o cujo deslocamento maximiza ou minimiza um valor especificado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crie aqui as fun√ß√µes que calculam as derivadas parciais de theta_0 e theta_1\n",
    "# n√£o esque√ßa os par√¢metros\n",
    "\n",
    "def dif_theta_0(m, theta_1,xi,theta_0,yi):\n",
    "    drv_theta_0 = 2 / m * (theta_1*xi + theta_0 - yi)\n",
    "    return drv_theta_0\n",
    "    \n",
    "def dif_theta_1(m, theta_1, xi, theta_0, yi):\n",
    "    drv_theta_1 = 2/m * (theta_1*xi + theta_0 - yi) * xi\n",
    "    return drv_theta_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, agora voc√™ tem tudo que precisa para montar o modelo, juntando todas as ideias obtidas at√© aqui, o processo por meio do qual voc√™ ir√° iterar os par√¢metros da sua regress√£o √© o seguinte:\n",
    "\n",
    "$$\\theta_{i+1} = \\theta_{i} - \\mu\\frac{\\partial}{\\partial\\theta}EQM$$\n",
    "\n",
    "Onde\n",
    "\n",
    "$\\theta_i$ √© o valor de $\\theta$ (0 ou 1) na i-√©sima itera√ß√£o;\n",
    "\n",
    "$\\mu$ √© o learning rate.\n",
    "\n",
    "Com isso, voc√™ pode achar o par√¢metros da regress√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crie aqui a fun√ß√£o que realiza a itera√ß√£o de theta\n",
    "\n",
    "def itera_theta(theta_0, theta_1, learning_rate, drv_theta_0, drv_theta_1):\n",
    "    theta_0 = theta_0 - learning_rate * drv_theta_0\n",
    "    theta_1 = theta_1 - learning_rate * drv_theta_1\n",
    "    return theta_0,theta_1       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-7.73222767231071 2.202885641865705\n"
     ]
    }
   ],
   "source": [
    "# Programa Princial\n",
    "\n",
    "xi = 0 \n",
    "yi = 0 \n",
    "drv_theta_0 = 0 \n",
    "drv_theta_1 = 0\n",
    "\n",
    "for i in range(iteracoes):\n",
    "    for i in range(m):\n",
    "        xi = dataset['X'][i]\n",
    "        yi = dataset['y'][i]\n",
    "        drv_theta_0 = dif_theta_0(m, theta_1,xi,theta_0,yi)\n",
    "        drv_theta_1 =dif_theta_1(m, theta_1,xi,theta_0,yi)\n",
    "        theta_0, theta_1 = itera_theta(theta_0, theta_1, learning_rate, drv_theta_0, drv_theta_1)\n",
    "        eqm = calcula_eqm(m,theta_1, theta_0, yi)\n",
    "\n",
    "print(theta_0, theta_1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plote um gr√°fico contendo:\n",
    "#  Os valores reais de X e y\n",
    "#  A reta formada pelos valores de  ùúÉ  encontrados por voc√™\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "reta = theta_1 * dataset['X'] + theta_0 \n",
    "\n",
    "plt.scatter(dataset['X'],dataset['y'], color = 'pink')  \n",
    "plt.plot(dataset['X'],reta, color = 'red')         \n",
    "plt.title('Gr√°fico de Regress√£o Linear') \n",
    "plt.ylabel('Valores de y')                \n",
    "plt.xlabel('Valores de x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FONTES\n",
    "\n",
    "# Fonte de estudo usada para entender melhor ainda como funciona o M√©todo do Gradiente Descendente:\n",
    "#   Gradiente Descendente - Um m√©todo poderoso e flex√≠vel para otimiza√ß√£o iterativa:  https://matheusfacure.github.io/2017/02/20/MQO-Gradiente-Descendente/\n",
    "#   Regress√£o Linear com Gradiente Descendente: https://medium.com/@bruno.dorneles/regress%C3%A3o-linear-com-gradiente-descendente-d3420b0b0ff\n",
    "\n",
    "\n",
    "# Fontes de estudo usadas para relembrar como criar e usar Fun√ß√µes:\n",
    "#   Curso Python #20 - Fun√ß√µes (Parte 1):  https://www.youtube.com/watch?v=ezfr9d7wd_k\n",
    "#   Fun√ß√µes - Como pensar como um Cientista da Computa√ß√£o: https://panda.ime.usp.br/pensepy/static/pensepy/05-Funcoes/funcoes.html#:~:text=Na%20defini%C3%A7%C3%A3o%20de%20uma%20fun%C3%A7%C3%A3o,caso%2C%20os%20par%C3%AAnteses%20s%C3%A3o%20obrigat%C3%B3rios.\n",
    "\n",
    "\n",
    "# Fonte de consulta para descobrir o significado de um erro do algoritmo:\n",
    "#    Python TypeError with ufunc bitwise_xor:   https://stackoverflow.com/questions/22725421/typeerror-with-ufunc-bitwise-xor\n",
    "\n",
    "# Fonte para descobrir porque a imagem do meu gr√°fico n√£o aparecia quando eu rodava todas as c√©lulas de uma vez:\n",
    "#     Jupyter Notebook - Plot inside a function - Figure is not plotted [duplicate]:  https://stackoverflow.com/questions/52862234/jupyter-notebook-plot-inside-a-function-figure-is-not-plotted/52862586\n",
    "\n",
    "# Tamb√©m consultei o Tutorial fornecido pela Talus para aprender a importar um dataset no Notebook & para relembrar os comandos de plotar gr√°ficos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pronto, a partir daqui √© com voc√™. Mas n√≥s vamos dar mais uma m√£ozinha. N√≥s preparamos um roteiro e __ATEN√á√ÉO__ todos os pontos s√£o __OBRIGAT√ìRIOS__ mas a execu√ß√£o √© totalmente por sua conta.\n",
    "\n",
    "- Leia o arquivo \"desafio.csv\" na pasta data\n",
    "- Obtenha as vari√°veis X e y no dataset\n",
    "- Inicialize (e deixe bem claro onde fez isso) os par√¢metros de seu modelo:\n",
    "    - Learning rate;\n",
    "    - N√∫mero de itera√ß√µes;\n",
    "    - N√∫mero de amostras;\n",
    "    - $\\theta_0$ e $\\theta_1$ iniciais, gerados aleatoriamente.\n",
    "- Desenvolva a fun√ß√£o que calcula EQM\n",
    "- Desenvolva uma (ou duas) fun√ß√µes que devolva a derivada parcial de EQM para cada um dos $\\theta$\n",
    "- Desenvolva a fun√ß√£o que itera $\\theta_0$ e $\\theta_1$ e devolva os valores finais\n",
    "- Plote um gr√°fico contendo:\n",
    "    - Os valores reais de X e y\n",
    "    - A reta formada pelos valores de $\\theta$ encontrados por voc√™\n",
    "    \n",
    "Ainda que voc√™ n√£o consiga concretizar um dos passos, N√ÉO desista. Novamente, o foco n√£o √© no resultado, mas na qualidade de seu c√≥digo.\n",
    "\n",
    "__BOA SORTE!__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
